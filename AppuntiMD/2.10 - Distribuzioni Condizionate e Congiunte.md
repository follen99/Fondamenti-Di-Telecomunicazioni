# Raccolta di esercizi

## Esercizio sul calcolo della media di due variabili aleatorie

In questo caso viene usato il calcolo di una variabile di tipo Mixture in modo da calcolare la media di due variabili aleatorie.

# Caratterizzazione congiunta di due variabili aleatorie

Dobbiamo fare un passo indietro: **consideriamo la CDF congiunta di X e Y:**

Pensiamo al caso in cui vogliamo valutare la probabilità che l'altezza sia minore di 160cm ed il peso sia minore di 70kg; quindi cosa stiamo valutando?

![image-20230110105858779](./assets/image-20230110105858779.png)

> Possiamo considerare un qualsiasi esperimento aleatorio che prenda in considerazione **due aspetti diversi** dello stesso esperimento (ie: altezza e peso)

Attraverso una caratterizzazione congiunta (sia X che Y), dove "arriviamo"?

![image-20230110110254655](./assets/image-20230110110254655.png)

Non avremo più uno spazio **unidimensionale**, ma ne avremo uno **bidimensionale**, ovvero un asse x ed uno y; data la coppia (x,y) stiamo valutando la probabilità relativa al rettangolo, che corrisponde proprio a:

![image-20230110110417865](./assets/image-20230110110417865.png)

> La probabilità che X sia minore di x **contemporaneamente** alla probabilità che Y sia minore di y.

Ricordandoci della definizione di **eventi indipendenti** (visti nella lezione) possiamo scrivere la probabilità come:

![image-20230110111446673](./assets/image-20230110111446673.png)

Non è però detto che l'uguaglianza si verifichi: basti pensare proprio all'esempio di altezza e peso, queste due **non sono indipendenti!**.

Dobbiamo quindi andare a definire le **CDF congiunte** delle nostre variabili aleatorie:

## CDF congiunta

Definiamo la CDF congiunta proprio come una Funzione delle variabili (x,y) definita non più in R ma in R<sup>2</sup>, la funzione:

![image-20230110111826905](./assets/image-20230110111826905.png)

## PDF e PMF congiunte

![image-20230110112615890](./assets/image-20230110112615890.png)

> Ricordiamo che la PMF è una probabilità menter la PDF non lo è;
>
> Inoltre anche le CDF, PMF e PDF <u>congiunte</u> godono delle proprietà viste con le CDF, PMF e PDF.



# Distribuzioni Condizionate ad un EVENTO B

Si definisce CDF condizionata a B:

![image-20230110113433131](./assets/image-20230110113433131.png)

## PMF condizionata

![image-20230110113455486](./assets/image-20230110113455486.png)

PDF condizionata

![image-20230110113509177](./assets/image-20230110113509177.png)

### Esempio - Radar ad impulsi

![image-20230110195459264](./assets/image-20230110195459264.png)

![image-20230110195516714](./assets/image-20230110195516714.png)

![image-20230110195530444](./assets/image-20230110195530444.png)

# Distribuzioni Condizionate ad una VARIABILE ALEATORIA Y

## PMF

![image-20230110195709206](./assets/image-20230110195709206.png)

## PDF

![image-20230110195726390](./assets/image-20230110195726390.png)

## Leggi della probabilità per la PDF

![image-20230110195748391](./assets/image-20230110195748391.png)

# Variabili Aleatorie Statisticamente Indipendenti

## Per variabili aleatorie discrete

![image-20230110195828858](./assets/image-20230110195828858.png)

## Per variabili aleatorie continue

![image-20230110195845157](./assets/image-20230110195845157.png)

### PDF generalizzata per v.a. statisticamente indipendenti

![image-20230110195911935](./assets/image-20230110195911935.png)

# Caratterizzazione congiunta sintetica - Momenti Congiunti di ordine k

È definita allo stesso modo dei momenti di v.a. singole:

![image-20230110200005064](./assets/image-20230110200005064.png)

Il vantaggio dei momenti congiunti di ordine k è che essi contengono "tutti i momenti", anche di variabili singole:

![image-20230110200151719](./assets/image-20230110200151719.png)

Se poniamo m = 1 ed r = 1 otteniamo la Correlazione di x ed y

## Correlazione di (x,y) - Media di (x,y)

![image-20230110200249304](./assets/image-20230110200249304.png)

# Momenti Centrali Congiunti

![image-20230110201108685](./assets/image-20230110201108685.png)

Anche in questo caso il momento centrale congiunto di ordine k racchiude "tutti i momenti", compresa la varianza, che è proprio un **momento centrale di ordine 2**.

Se poniamo m = 2 ed r = 0 otteniamo proprio la varianza:

![image-20230110201328048](./assets/image-20230110201328048.png)

## Covarianza

Se poniamo m = 1 ed r = 1 otteniamo la covarianza:

![image-20230110201411975](./assets/image-20230110201411975.png)

La covarianza è una misura che ci dice **come due variabili cambiano insieme, in altre parole, ci dice se c'è una relazione lineare tra due variabili.**

A seconda del valore della covarianza abbiamo:

- C<sub>XY</sub> > 0 : **le due variabili x ed y aumentano e diminuiscono insieme**
- C<sub>XY</sub> < 0 : **quando una variabile aumenta, l'altra diminuisce e viceversa**
- C<sub>XY</sub> = 0 : **non c'è correlazione tra le due variabili**

Quando la covarianza è zero, vuol dire che non c'è correlazione tra le due variabili, si dicono quindi **incorrelate**.

---

## Esprimere la Correlazione tramite la Covarianza

Possiamo esprimere la correlazione tramite la Covarianza andando ad **esplicitare la media** (facciamo i calcoli e sostituiamo quà e là):

![image-20230110202824974](./assets/image-20230110202824974.png)

## Cosa succede quando due variabili sono incorrelate?

![image-20230110203119007](./assets/image-20230110203119007.png)

Quando due variabili sono incorrelate ed andiamo a calcolarne la media (Correlazione) otteniamo il prodotto delle medie delle due variabili.

# Variabili Gaussiane Congiunte

![image-20230110203259344](./assets/image-20230110203259344.png)